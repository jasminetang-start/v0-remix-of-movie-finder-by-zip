# Cinema Aggregator

## ğŸ¬ Project Overview

This monorepo contains:
- **Backend Scraper** (Python) - Scrapes cinema websites for showtimes
- **Data Storage** (JSON) - Versioned showtime data in `data/`
- **Frontend Website** (Coming soon) - Web interface to browse movies
- **GitHub Actions** - Automated daily scraping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub     â”‚ 
â”‚  Actions    â”‚ â”€â”€â”
â”‚  (6AM UTC)  â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Scraper â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   data/  â”‚
            â”‚  (Python)â”‚        â”‚   JSON   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ Frontend â”‚
                                â”‚ Website  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Supported Cinemas

| Cinema | Status | Location |
|--------|--------|----------|
| SIFF | âœ… Working | Seattle, WA |
| VIFF | âš ï¸ Placeholder | Vancouver, BC |

---

## ğŸ“ Project Structure

```
cinema-aggregator/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily-scrape.yml     # GitHub Action for daily scraping
â”‚
â”œâ”€â”€ scraper/                     # Backend scraper (Python)
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                  # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                  # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ main_config.py       # Global settings
â”‚   â”‚   â””â”€â”€ cinemas.py           # Cinema-specific configs
â”‚   â”‚
â”‚   â”œâ”€â”€ common/                  # Shared utilities
â”‚   â”‚   â”œâ”€â”€ base_scraper.py      # Base scraper class
â”‚   â”‚   â”œâ”€â”€ base_processor.py    # Base processor class
â”‚   â”‚   â””â”€â”€ omdb_client.py       # OMDb API client
â”‚   â”‚
â”‚   â””â”€â”€ scrapers/                # Cinema-specific scrapers
â”‚       â”œâ”€â”€ siff/
â”‚       â”‚   â”œâ”€â”€ scraper.py
â”‚       â”‚   â””â”€â”€ processor.py
â”‚       â””â”€â”€ viff/
â”‚           â”œâ”€â”€ scraper.py
â”‚           â””â”€â”€ processor.py
â”‚
â”œâ”€â”€ data/                        # Scraped data (Git-tracked)
â”‚   â”œâ”€â”€ movies.json              # Combined all cinemas
â”‚   â”œâ”€â”€ siff_movies.json         # SIFF-specific
â”‚   â”œâ”€â”€ viff_movies.json         # VIFF-specific
â”‚   â””â”€â”€ metadata.json            # Scraping metadata
â”‚
â””â”€â”€ website/                     # Frontend (Coming soon)
    â””â”€â”€ ...
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Google Chrome browser
- Git

### Setup Scraper

```bash
# Clone repository
git clone https://github.com/startfilmstudio/cinema-aggregator.git
cd cinema-aggregator

# Navigate to scraper
cd scraper

# Create virtual environment
python3 -m venv siff_env
source siff_env/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run scraper
python main.py
```

### Run Specific Scrapers

```bash
# Run all enabled scrapers
python main.py

# Run only SIFF
python main.py --scrapers siff

# Run only VIFF
python main.py --scrapers viff

# Run multiple
python main.py --scrapers siff viff
```

---

## âš™ï¸ Configuration

### Global Settings

Edit `scraper/config/main_config.py`:

```python
# Which scrapers to run
ENABLED_SCRAPERS = ["siff", "viff"]

# OMDb enrichment
OMDB_API_KEY = "your_key_here"
USE_OMDB_ENRICHMENT = True

# Request settings
REQUEST_DELAY = 1  # seconds between requests
USE_HEADLESS = True  # run browser in background
```

### Cinema Settings

Edit `scraper/config/cinemas.py`:

```python
CINEMAS = {
    "siff": {
        "base_url": "https://www.siff.net",
        "days_to_scrape": [0, 1, 2, 3, 4, 5, 6],
        "venues": {
            "SIFF Cinema Uptown": "SIFF_UPTOWN",
            ...
        }
    },
    ...
}
```

---

## ğŸ“Š Output Format

### Combined Output (`data/movies.json`)

```json
[
  {
    "movie": {
      "title": "After the Hunt",
      "url": "https://www.siff.net/...",
      "image_url": "https://www.siff.net/images/...",
      "country": "USA",
      "year": 2025,
      "duration": 139,
      "director": "Luca Guadagnino",
      "imdb_id": "tt15239678",
      "imdb_rating": "8.2",
      "plot": "College professor...",
      "genre": "Drama, Thriller",
      "ratings": {
        "imdb": "8.2/10",
        "rotten_tomatoes": "89%"
      }
    },
    "cinema_id": "SIFF_UPTOWN",
    "showtimes": [
      { "show_date": "2025-10-20", "show_time": "19:15" },
      { "show_date": "2025-10-21", "show_time": "19:15" }
    ],
    "scraped_at": "2025-10-20"
  }
]
```

### Metadata (`data/metadata.json`)

```json
{
  "last_updated": "2025-10-20T14:30:00Z",
  "total_movies": 45,
  "cinemas": {
    "siff": {
      "movie_count": 25,
      "last_scraped": "2025-10-20T14:25:00Z",
      "status": "success"
    },
    "viff": {
      "movie_count": 20,
      "status": "success"
    }
  }
}
```

---

## ğŸ¤– GitHub Actions

### Automated Daily Scraping

The scraper runs automatically every day at **6:00 AM UTC** (11 PM PST).

**Workflow:** `.github/workflows/daily-scrape.yml`

```yaml
on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC
  workflow_dispatch:      # Manual trigger
```

### Manual Trigger

1. Go to **Actions** tab
2. Select **Daily Movie Scraper**
3. Click **Run workflow**
4. Optional: Specify scrapers (e.g., `siff,viff`)

### Setup GitHub Secrets

For OMDb API enrichment, add your API key:

1. Go to **Settings** â†’ **Secrets** â†’ **Actions**
2. Click **New repository secret**
3. Name: `OMDB_API_KEY`
4. Value: Your OMDb API key
5. Click **Add secret**

---

## ğŸŒ Frontend Website

### Coming Soon

The frontend will:
- Display movies from `data/movies.json`
- Filter by cinema, date, genre
- Show ratings and showtimes
- Auto-deploy on data updates

### Tech Stack (Planned)

- Framework: Next.js / React
- Deployment: Vercel / Netlify
- Auto-deploy: Triggered by GitHub commits to `data/`

---

## ğŸ› ï¸ Adding New Cinemas

### Step 1: Add Configuration

Edit `scraper/config/cinemas.py`:

```python
"amc": {
    "name": "AMC Theatres",
    "base_url": "https://www.amctheatres.com",
    "days_to_scrape": [0, 1, 2, 3, 4, 5, 6],
    "output_file": "amc_movies.json",
    "venues": {
        "AMC Pacific Place 11": "AMC_PACIFIC",
        ...
    }
}
```

### Step 2: Create Scraper

Create `scraper/scrapers/amc/scraper.py`:

```python
from common.base_scraper import BaseScraper

class AMCScraper(BaseScraper):
    # Implement AMC-specific scraping logic
    ...
```

### Step 3: Create Processor

Create `scraper/scrapers/amc/processor.py`:

```python
from common.base_processor import BaseProcessor

class AMCProcessor(BaseProcessor):
    # Implement AMC-specific processing logic
    ...
```

### Step 4: Register in Main Script

Edit `scraper/main.py` - add AMC import and conditional.

### Step 5: Enable

Edit `scraper/config/main_config.py`:

```python
ENABLED_SCRAPERS = ["siff", "viff", "amc"]
```

---

## ğŸ› Troubleshooting

### Scraper Issues

**Problem:** ChromeDriver error

**Solution:**
```bash
pip install --upgrade webdriver-manager
```

---

**Problem:** No data scraped

**Solution:**
- Website structure may have changed
- Update selectors in `scrapers/{cinema}/scraper.py`
- Set `USE_HEADLESS = False` to see browser

---

**Problem:** OMDb API errors

**Solution:**
- Check API key in config
- Verify daily limit (1,000 requests/day free tier)
- Set `USE_OMDB_ENRICHMENT = False` to disable

---

### GitHub Actions Issues

**Problem:** Action fails to commit

**Solution:**
- Verify GitHub Actions has write permissions
- Go to **Settings** â†’ **Actions** â†’ **General**
- Enable "Read and write permissions"

---

**Problem:** Scraper fails in Actions but works locally

**Solution:**
- Check `OMDB_API_KEY` secret is set
- Verify Chrome installation in workflow
- Check action logs for specific errors

---

## ğŸ“ Development

### Local Development

```bash
# Activate virtual environment
cd scraper
source siff_env/bin/activate

# Run with verbose output
python main.py

# Test specific scraper
python main.py --scrapers siff

# Disable OMDb (faster testing)
# Edit config/main_config.py: USE_OMDB_ENRICHMENT = False
```

### Testing Changes

Before committing:

1. Run scraper locally: `python main.py`
2. Verify output in `../data/`
3. Check `data/metadata.json` for errors
4. Commit changes

---

## ğŸ“„ License

This project is provided as-is for educational purposes.

---

## ğŸ™ Acknowledgments

- [OMDb API](http://www.omdbapi.com/) - Movie database
- [Selenium](https://www.selenium.dev/) - Web automation
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) - HTML parsing
- [GitHub Actions](https://github.com/features/actions) - CI/CD

---

## ğŸ“§ Contact

- **GitHub:** [@startfilmstudio](https://github.com/startfilmstudio)
- **Repository:** [cinema-aggregator](https://github.com/startfilmstudio/cinema-aggregator)

---

**Happy scraping! ğŸ¬ğŸ¿**